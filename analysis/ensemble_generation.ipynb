{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Generation\n",
    "\n",
    "In this notebook we create the shuffled ensembles of annotated hypergraphs and calculate the features of the new shuffled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "from ahyper import AnnotatedHypergraph\n",
    "from ahyper.ensemble import data_features, shuffled_ensemble_features, save_feature_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "from ahyper.utils import (average_entropy, average_value, variance_value, entropy_value)\n",
    "from ahyper.observables import (_degree_centrality,\n",
    "                                _pagerank_centrality,\n",
    "                                _eigenvector_centrality,\n",
    "                                _connected_components,\n",
    "                                _assortativity,\n",
    "                                node_role_participation,\n",
    "                                local_role_density)\n",
    "\n",
    "INTERACTION_MAP = {'enron':np.array([[0,1,0.25],[0,0,0],[0,0,0]]),\n",
    "                   'twitter':np.array([[0,0.75,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,1]]),\n",
    "                   'movielens':np.array([[0,1,],[0.25,0.25]]),\n",
    "                   'stack_overflow':np.array([[0,0.1,0.1],[0.3,0.3,0.3],[1,0.5,0]]),\n",
    "                   'math_overflow':np.array([[0,0.1,0.1],[0.3,0.3,0.3],[1,0.5,0]]),\n",
    "                   'scopus_multilayer':np.array([[0,1,0.5],[0.2,0.2,0.2],[1,0.25,0]])\n",
    "                   }\n",
    "\n",
    "FEATURES = {'weighted_degree_entropy': {'func':entropy_value(_degree_centrality),\n",
    "                                'acts_on':'weighted_projection',\n",
    "                                'kwargs':{}\n",
    "                               },\n",
    "#             'weighted_pagerank_entropy': {'func':entropy_value(_pagerank_centrality),\n",
    "#                                 'acts_on':'weighted_projection',\n",
    "#                                 'kwargs':dict(weight='weight')\n",
    "#                                },\n",
    "#             'weighted_pagerank_variance': {'func':variance_value(_pagerank_centrality),\n",
    "#                                 'acts_on':'weighted_projection',\n",
    "#                                 'kwargs':dict(weight='weight')\n",
    "#                                },\n",
    "            'assortativity':{'func': _assortativity,\n",
    "                             'acts_on':'annotated_hypergraph',\n",
    "                             'kwargs':dict(n_samples=100000, by_role=True, spearman=True)},\n",
    "#             'weighted_eigenvector_entropy': {'func':entropy_value(_eigenvector_centrality),\n",
    "#                                 'acts_on':'weighted_projection',\n",
    "#                                 'kwargs':{}\n",
    "#                                },\n",
    "#             'connected_components': {'func':_connected_components,\n",
    "#                                 'acts_on':'weighted_projection',\n",
    "#                                 'kwargs':{}\n",
    "#                                },\n",
    "#             'node_role_entropy': {'func':average_entropy(node_role_participation),\n",
    "#                                 'acts_on':'annotated_hypergraph',\n",
    "#                                 'kwargs':dict(absolute_values=False)\n",
    "#                                },\n",
    "#             'neighbourhood_role_entropy': {'func':average_entropy(local_role_density),\n",
    "#                                 'acts_on':'annotated_hypergraph',\n",
    "#                                 'kwargs':dict(absolute_values=False, include_focus=False)\n",
    "#                                },\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "\n",
    "rc = ipp.Client()\n",
    "dview = rc[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] /annotated\r\n",
      "[stdout:1] /annotated\r\n",
      "[stdout:2] /annotated\r\n",
      "[stdout:3] /annotated\r\n",
      "[stdout:4] /annotated\r\n",
      "[stdout:5] /annotated\r\n"
     ]
    }
   ],
   "source": [
    "%px !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%px\n",
    "DATASETS = ['enron','math_overflow','movielens','scopus_multilayer','stack_overflow','twitter']\n",
    "\n",
    "def process_study(data_name):\n",
    "    \n",
    "    print(data_name)\n",
    "    start = time()\n",
    "    \n",
    "    A = AnnotatedHypergraph.from_incidence(data_name, \n",
    "                                           root='./data/',\n",
    "                                           relabel_roles=False,\n",
    "                                           add_metadata=False)\n",
    "    \n",
    "    A.assign_role_interaction_matrix(INTERACTION_MAP[data_name])\n",
    "    \n",
    "    save_feature_study(A,\n",
    "                       data_name=f'{data_name}_as',\n",
    "                       shuffle_fraction=0.1, \n",
    "                       num_shuffles=500,\n",
    "                       features=FEATURES,\n",
    "                       burn_fraction=200,\n",
    "                       root='./results/',\n",
    "                       verbose=True,\n",
    "                       fail_hard=False\n",
    "                       )\n",
    "    \n",
    "    end = time()\n",
    "    \n",
    "    return (end-start)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_study('enron')\n",
    "parallel_result = dview.map_async(process_study, DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.130711, [None, None, None, None, None, None])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_result.elapsed, parallel_result.completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_result.elapsed//(60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enron\\nRunning Role Preserving MCMC...\\n0.0%\\r5.0%\\r10.0%\\r15.0%\\r20.0%\\r25.0%\\r30.0%\\r35.0%\\r40.0%\\r45.0%\\r50.0%\\r55.0%\\r60.0%\\r65.0%\\r70.0%\\r75.0%\\r80.0%\\r85.0%\\r90.0%\\r95.0%\\rRunning Role Destroying MCMC...\\n0.0%\\r5.0%\\r10.0%\\r15.0%\\r20.0%\\r25.0%\\r30.0%\\r35.0%\\r40.0%\\r45.0%\\r50.0%\\r55.0%\\r60.0%\\r65.0%\\r70.0%\\r75.0%\\r80.0%\\r85.0%\\r90.0%\\r95.0%\\r',\n",
       " 'math_overflow\\nRunning Role Preserving MCMC...\\n0.0%\\r5.0%\\r10.0%\\r15.0%\\r20.0%\\r25.0%\\r30.0%\\r35.0%\\r40.0%\\r45.0%\\r50.0%\\r55.0%\\r60.0%\\r65.0%\\r70.0%\\r75.0%\\r80.0%\\r85.0%\\r90.0%\\r95.0%\\r',\n",
       " 'movielens\\n',\n",
       " 'scopus_multilayer\\n',\n",
       " 'stack_overflow\\nRunning Role Preserving MCMC...\\n0.0%\\r5.0%\\r10.0%\\r15.0%\\r20.0%\\r25.0%\\r30.0%\\r35.0%\\r40.0%\\r45.0%\\r50.0%\\r55.0%\\r60.0%\\r65.0%\\r70.0%\\r75.0%\\r80.0%\\r85.0%\\r90.0%\\r95.0%\\r',\n",
       " 'twitter\\n']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_result.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'msg_id': '517dbaba-1785dac91609606a38a1e6be',\n",
       "  'submitted': datetime.datetime(2019, 10, 1, 10, 30, 46, 79924, tzinfo=tzlocal()),\n",
       "  'started': datetime.datetime(2019, 10, 1, 10, 30, 46, 91905, tzinfo=tzlocal()),\n",
       "  'completed': datetime.datetime(2019, 10, 1, 11, 57, 21, 848330, tzinfo=tzlocal()),\n",
       "  'received': datetime.datetime(2019, 10, 1, 11, 57, 21, 858398, tzinfo=tzutc()),\n",
       "  'engine_uuid': '0024ef03-a41eb7f01a757a20f4661eaa',\n",
       "  'engine_id': 0,\n",
       "  'follow': [],\n",
       "  'after': [],\n",
       "  'status': 'ok',\n",
       "  'execute_input': None,\n",
       "  'execute_result': None,\n",
       "  'error': None,\n",
       "  'stdout': 'enron\\nRunning Role Preserving MCMC...\\n0.0%\\r5.0%\\r10.0%\\r15.0%\\r20.0%\\r25.0%\\r30.0%\\r35.0%\\r40.0%\\r45.0%\\r50.0%\\r55.0%\\r60.0%\\r65.0%\\r70.0%\\r75.0%\\r80.0%\\r85.0%\\r90.0%\\r95.0%\\rRunning Role Destroying MCMC...\\n0.0%\\r5.0%\\r10.0%\\r15.0%\\r20.0%\\r25.0%\\r30.0%\\r35.0%\\r40.0%\\r45.0%\\r50.0%\\r55.0%\\r60.0%\\r65.0%\\r70.0%\\r75.0%\\r80.0%\\r85.0%\\r90.0%\\r95.0%\\r',\n",
       "  'stderr': '',\n",
       "  'outputs': [],\n",
       "  'data': {}},\n",
       " {'msg_id': '6741dc56-3edf3a095c0239cfacafa7e3',\n",
       "  'submitted': datetime.datetime(2019, 10, 1, 10, 30, 46, 81341, tzinfo=tzlocal()),\n",
       "  'started': datetime.datetime(2019, 10, 1, 10, 30, 46, 94167, tzinfo=tzlocal()),\n",
       "  'completed': datetime.datetime(2019, 10, 1, 11, 7, 12, 33255, tzinfo=tzlocal()),\n",
       "  'received': datetime.datetime(2019, 10, 1, 11, 7, 12, 41500, tzinfo=tzutc()),\n",
       "  'engine_uuid': 'de96f232-281fe2c8836b4f42b203373f',\n",
       "  'engine_id': 1,\n",
       "  'follow': [],\n",
       "  'after': [],\n",
       "  'status': 'error',\n",
       "  'execute_input': None,\n",
       "  'execute_result': None,\n",
       "  'error': <Remote[1]:OSError([Errno 5] Input/output error: '/annotated')>,\n",
       "  'stdout': 'math_overflow\\nRunning Role Preserving MCMC...\\n0.0%\\r5.0%\\r10.0%\\r15.0%\\r20.0%\\r25.0%\\r30.0%\\r35.0%\\r40.0%\\r45.0%\\r50.0%\\r55.0%\\r60.0%\\r65.0%\\r70.0%\\r75.0%\\r80.0%\\r85.0%\\r90.0%\\r95.0%\\r',\n",
       "  'stderr': '',\n",
       "  'outputs': [],\n",
       "  'data': {}},\n",
       " {'msg_id': None,\n",
       "  'submitted': datetime.datetime(2019, 10, 1, 10, 30, 46, 82784, tzinfo=tzutc()),\n",
       "  'started': None,\n",
       "  'completed': None,\n",
       "  'received': None,\n",
       "  'engine_uuid': None,\n",
       "  'engine_id': None,\n",
       "  'follow': None,\n",
       "  'after': None,\n",
       "  'status': None,\n",
       "  'execute_input': None,\n",
       "  'execute_result': None,\n",
       "  'error': None,\n",
       "  'stdout': 'movielens\\n',\n",
       "  'stderr': '',\n",
       "  'outputs': [],\n",
       "  'data': {}},\n",
       " {'msg_id': None,\n",
       "  'submitted': datetime.datetime(2019, 10, 1, 10, 30, 46, 84008, tzinfo=tzutc()),\n",
       "  'started': None,\n",
       "  'completed': None,\n",
       "  'received': None,\n",
       "  'engine_uuid': None,\n",
       "  'engine_id': None,\n",
       "  'follow': None,\n",
       "  'after': None,\n",
       "  'status': None,\n",
       "  'execute_input': None,\n",
       "  'execute_result': None,\n",
       "  'error': None,\n",
       "  'stdout': 'scopus_multilayer\\n',\n",
       "  'stderr': '',\n",
       "  'outputs': [],\n",
       "  'data': {}},\n",
       " {'msg_id': '9f3f23e8-f7c215101491ae7d7106eac8',\n",
       "  'submitted': datetime.datetime(2019, 10, 1, 10, 30, 46, 85154, tzinfo=tzlocal()),\n",
       "  'started': datetime.datetime(2019, 10, 1, 10, 30, 46, 101059, tzinfo=tzlocal()),\n",
       "  'completed': datetime.datetime(2019, 10, 1, 13, 29, 56, 412815, tzinfo=tzlocal()),\n",
       "  'received': datetime.datetime(2019, 10, 1, 13, 29, 56, 418490, tzinfo=tzutc()),\n",
       "  'engine_uuid': '8aeb2c1a-8a970212d24b24b03959b138',\n",
       "  'engine_id': 4,\n",
       "  'follow': [],\n",
       "  'after': [],\n",
       "  'status': 'error',\n",
       "  'execute_input': None,\n",
       "  'execute_result': None,\n",
       "  'error': <Remote[4]:OSError([Errno 5] Input/output error: '/annotated')>,\n",
       "  'stdout': 'stack_overflow\\nRunning Role Preserving MCMC...\\n0.0%\\r5.0%\\r10.0%\\r15.0%\\r20.0%\\r25.0%\\r30.0%\\r35.0%\\r40.0%\\r45.0%\\r50.0%\\r55.0%\\r60.0%\\r65.0%\\r70.0%\\r75.0%\\r80.0%\\r85.0%\\r90.0%\\r95.0%\\r',\n",
       "  'stderr': '',\n",
       "  'outputs': [],\n",
       "  'data': {}},\n",
       " {'msg_id': None,\n",
       "  'submitted': datetime.datetime(2019, 10, 1, 10, 30, 46, 86645, tzinfo=tzutc()),\n",
       "  'started': None,\n",
       "  'completed': None,\n",
       "  'received': None,\n",
       "  'engine_uuid': None,\n",
       "  'engine_id': None,\n",
       "  'follow': None,\n",
       "  'after': None,\n",
       "  'status': None,\n",
       "  'execute_input': None,\n",
       "  'execute_result': None,\n",
       "  'error': None,\n",
       "  'stdout': 'twitter\\n',\n",
       "  'stderr': '',\n",
       "  'outputs': [],\n",
       "  'data': {}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_result.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[4:7]: \u001b[0m\n",
       "['enron',\n",
       " 'math_overflow',\n",
       " 'movielens',\n",
       " 'scopus_multilayer',\n",
       " 'stack_overflow',\n",
       " 'twitter']"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2019-10-01T14:12:09.096535",
      "data": {},
      "engine_id": 4,
      "engine_uuid": "8aeb2c1a-8a970212d24b24b03959b138",
      "error": null,
      "execute_input": "\nDATASETS\n",
      "execute_result": {
       "data": {
        "text/plain": "['enron',\n 'math_overflow',\n 'movielens',\n 'scopus_multilayer',\n 'stack_overflow',\n 'twitter']"
       },
       "execution_count": 7,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "e8494476-32a2f216f6095b0539a89aff",
      "outputs": [],
      "received": "2019-10-01T14:12:09.103583",
      "started": "2019-10-01T14:12:09.062534",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2019-10-01T14:12:09.054164"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%px --targets 4\n",
    "\n",
    "DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: enron\n",
      "Running Role Preserving MCMC...\n",
      "Running Role Destroying MCMC...\n",
      "DATASET: math_overflow\n",
      "Running Role Preserving MCMC...\n",
      "Running Role Destroying MCMC...\n",
      "DATASET: movielens\n",
      "Running Role Preserving MCMC...\n",
      "Running Role Destroying MCMC...\n",
      "0.0%\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ac5660ba898d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                        \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../results/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                        \u001b[0mfail_hard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                        )\n",
      "\u001b[0;32m/annotated/ahyper/ensemble.py\u001b[0m in \u001b[0;36msave_feature_study\u001b[0;34m(annotated_hypergraph, data_name, shuffle_fraction, num_shuffles, features, burn_fraction, role_preserving, role_destroying, root, verbose, fail_hard)\u001b[0m\n\u001b[1;32m    198\u001b[0m                                         \u001b[0mshuffle_algorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_MCMC_no_role'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                                         fail_hard=fail_hard)\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mrole_destroying_ensemble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrole_destroying_ensemble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/annotated/ahyper/ensemble.py\u001b[0m in \u001b[0;36mshuffled_ensemble_features\u001b[0;34m(annotated_hypergraph, shuffle_fraction, num_shuffles, features, burn_fraction, shuffle_algorithm, verbose, fail_hard)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muses_projection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_weighted_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_graphtool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/annotated/ahyper/annotated_hypergraph.py\u001b[0m in \u001b[0;36mto_weighted_projection\u001b[0;34m(self, use_networkx, use_graphtool, as_matrix)\u001b[0m\n\u001b[1;32m    395\u001b[0m                         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvertices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m                     \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/graph_tool/__init__.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(self, source, target, add_missing)\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \"\"\"\n\u001b[1;32m   2398\u001b[0m         e = libcore.add_edge(self.__graph,\n\u001b[0;32m-> 2399\u001b[0;31m                              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m                              self.vertex(int(target), add_missing=add_missing))\n\u001b[1;32m   2401\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/graph_tool/__init__.py\u001b[0m in \u001b[0;36mvertex\u001b[0;34m(self, i, use_index, add_missing)\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0mvertex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \"\"\"\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vertex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0madd_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATASETS = ['enron','math_overflow','movielens','scopus_multilayer','stack_overflow','twitter']\n",
    "# DATASETS = ['twitter']\n",
    "\n",
    "\n",
    "for data_name in DATASETS:\n",
    "    print(f'DATASET: {data_name}')\n",
    "    \n",
    "    A = AnnotatedHypergraph.from_incidence(data_name, \n",
    "                                           root='../data/',\n",
    "                                           relabel_roles=False,\n",
    "                                           add_metadata=False)\n",
    "    \n",
    "    save_feature_study(A,\n",
    "                       data_name=data_name,\n",
    "                       shuffle_fraction=0.1, \n",
    "                       num_shuffles=1000,\n",
    "#                        num_shuffles=20,\n",
    "                       features=FEATURES,\n",
    "#                        burn_fraction=None,\n",
    "                       burn_fraction=10,\n",
    "                       root='../results/',\n",
    "                       verbose=True,\n",
    "                       fail_hard=False\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specialised Role-interaction Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Role Preserving MCMC...\n",
      "Running Role Destroying MCMC...\n",
      "95.0%\r"
     ]
    }
   ],
   "source": [
    "A = AnnotatedHypergraph.from_incidence('enron', \n",
    "                                       root='../data/',\n",
    "                                       relabel_roles=False,\n",
    "                                       add_metadata=False)\n",
    "\n",
    "A.assign_role_interaction_matrix(np.array([[0.2,1,0.8],[0.2,0.2,0.2],[0.2,0.2,0.2]]))\n",
    "\n",
    "save_feature_study(A,\n",
    "                   data_name='enron_full',\n",
    "                   shuffle_fraction=0.1, \n",
    "                   num_shuffles=2000, \n",
    "                   features=FEATURES,\n",
    "                   burn_fraction=200,\n",
    "                   root='../results/',\n",
    "                   verbose=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StackOverFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = AnnotatedHypergraph.from_incidence('stack_overflow', \n",
    "                                       root='../data/',\n",
    "                                       relabel_roles=False,\n",
    "                                       add_metadata=False)\n",
    "\n",
    "A.assign_role_interaction_matrix(np.array([[0,0.1,0.1],[0.3,0.3,0.3],[1,0.5,0]]))\n",
    "\n",
    "save_feature_study(A,\n",
    "                   data_name='stack_overflow_r',\n",
    "                   shuffle_fraction=0.1, \n",
    "                   num_shuffles=1000, \n",
    "                   features=FEATURES,\n",
    "                   burn_fraction=10,\n",
    "                   root='../results/',\n",
    "                   verbose=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MathOverFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = AnnotatedHypergraph.from_incidence('math_overflow', \n",
    "                                       root='../data/',\n",
    "                                       relabel_roles=False,\n",
    "                                       add_metadata=False)\n",
    "\n",
    "A.assign_role_interaction_matrix(np.array([[0,0.1,0.1],[0.3,0.3,0.3],[1,0.5,0]]))\n",
    "\n",
    "save_feature_study(A,\n",
    "                   data_name='math_overflow_r',\n",
    "                   shuffle_fraction=0.1, \n",
    "                   num_shuffles=1000, \n",
    "                   features=FEATURES,\n",
    "                   burn_fraction=10,\n",
    "                   root='../results/',\n",
    "                   verbose=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scopus Multilayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = AnnotatedHypergraph.from_incidence('scopus_multilayer', \n",
    "                                       root='../data/',\n",
    "                                       relabel_roles=False,\n",
    "                                       add_metadata=False)\n",
    "\n",
    "A.assign_role_interaction_matrix(np.array([[0,1,0.5],[0.2,0.2,0.2],[1,0.25,0]]))\n",
    "\n",
    "save_feature_study(A,\n",
    "                   data_name='scopus_multilayer_r',\n",
    "                   shuffle_fraction=0.1, \n",
    "                   num_shuffles=1000, \n",
    "                   features=FEATURES,\n",
    "                   burn_fraction=10,\n",
    "                   root='../results/',\n",
    "                   verbose=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = AnnotatedHypergraph.from_incidence('twitter', \n",
    "                                       root='../data/',\n",
    "                                       relabel_roles=False,\n",
    "                                       add_metadata=False)\n",
    "\n",
    "#['source', 'target', 'retweeter', 'retweeted']\n",
    "A.assign_role_interaction_matrix(np.array([[0,0.75,0,0],[0,0,0,0],[0,0,0,0],[0,0,0,1]]))\n",
    "\n",
    "save_feature_study(A,\n",
    "                   data_name='twitter_r',\n",
    "                   shuffle_fraction=0.1, \n",
    "                   num_shuffles=1000, \n",
    "                   features=FEATURES,\n",
    "                   burn_fraction=10,\n",
    "                   root='../results/',\n",
    "                   verbose=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = A.to_weighted_projection(use_networkx=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import scipy.sparse as sp\n",
    "\n",
    "M = nx.to_scipy_sparse_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals, evecs = sp.linalg.eigs(M, k=1, return_eigenvectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = nx.stochastic_graph(G)\n",
    "M = nx.to_scipy_sparse_matrix(G)\n",
    "evals, evecs = sp.linalg.eigs(M, k=1, return_eigenvectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "plt.hist(evecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
